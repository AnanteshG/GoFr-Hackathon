{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d5cab6-515e-4dd6-95ae-6393f0c4435c",
   "metadata": {},
   "source": [
    "## Ingesting PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e8b999-83ba-484a-9b94-f56c201d2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --q unstructured langchain\n",
    "# %pip install --q \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0e2f74-7c4b-4665-8d87-bc00656f31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104c0b18-1c06-41a1-a2ca-f9ee23f4f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"data.txt\"\n",
    "\n",
    "# Local PDF file uploads\n",
    "if local_path:\n",
    "    loader = TextLoader(local_path, encoding=\"latin1\") \n",
    "    data = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38119195-9c91-4e58-aa46-8a74244032af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preview first page\n",
    "# data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2faacc1-be29-4d52-a46e-94f5b5b8e728",
   "metadata": {},
   "source": [
    "## Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dcf2cfe-a7aa-4ecf-85e3-f77b9e850514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39aebbf8-92bf-42e5-951e-40bb458852d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED               \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    Less than a second ago    \n",
      "llama3.2:latest            a80c4f17acd5    2.0 GB    3 hours ago               \n",
      "llama3:latest              365c0bd3c000    4.7 GB    4 hours ago               \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5394d61f-906b-4776-b8b5-9f0045c76193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\kruth\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\kruth\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --q chromadb\n",
    "%pip install --q langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4041e80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==5.26.1 in c:\\users\\kruth\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (5.26.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\kruth\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install protobuf==5.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a39856-0cc0-4ebe-8024-9db32455a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bad040e2-3abe-4e23-abb9-951b223b9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and chunk \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de5e70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kruth\\AppData\\Local\\Temp\\ipykernel_9916\\293498199.py:3: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True)\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "persistent_directory = os.path.join(current_dir, \"db\", \"chroma_db_for_GitHub\")\n",
    "embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb11c92-e732-4a88-8f57-57a19b38e383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kruth\\AppData\\Local\\Temp\\ipykernel_9916\\66197944.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing Chroma vector store.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(persistent_directory):\n",
    "    vector_db = Chroma(\n",
    "        persist_directory=persistent_directory, \n",
    "        embedding_function=embedding_function,\n",
    "        collection_name=\"local-rag\"\n",
    "    )\n",
    "    print(\"Loaded existing Chroma vector store.\")\n",
    "else:\n",
    "    vector_db = Chroma.from_documents(\n",
    "        documents=chunks, \n",
    "        embedding=OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True),\n",
    "        collection_name=\"local-rag\",\n",
    "        persist_directory=persistent_directory\n",
    "    )\n",
    "    vector_db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eadf50-2f3d-4420-8858-94e9c1682ffa",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec338c4-f282-462f-b0a0-c1899538eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d6ceeb-6883-4688-b923-e771c2b2cb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kruth\\AppData\\Local\\Temp\\ipykernel_9916\\2809591287.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=local_model)\n"
     ]
    }
   ],
   "source": [
    "# LLM from Ollama\n",
    "local_model = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c436d5cd-5dd0-448c-b5c0-6eddab879c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are a GitHub Repository who answers questions taking relevance from the data present in the vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e423dc-f632-46f8-9bec-d74cb268ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "template = \"\"\"You are a GitHub Repository. Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb1f308f-8472-4506-9517-d79b61d408f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8928589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "915fb18b-cb57-42cf-a9b3-c6f95d3c4e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chain.invoke(\"What is the contents present in the examples/using-web-socket/main.go file and which language is it? Please elaborate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2316714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `main.go` file contains an example of using WebSockets with the Go programming language. Here's a breakdown of the contents:\n",
      "\n",
      "```go\n",
      "package main\n",
      "\n",
      "import (\n",
      "\t\"fmt\"\n",
      "\t\"log\"\n",
      "\n",
      "\t\"github.com/gorilla/websocket\"\n",
      ")\n",
      "\n",
      "const (\n",
      "\twebsocketURL = \"ws://localhost:8080\"\n",
      ")\n",
      "\n",
      "var upgrader = websocket.Upgrader{\n",
      "\tReadBufferSize:  1024,\n",
      "\tWriteBufferSize: 1024,\n",
      "}\n",
      "\n",
      "type Contest struct {\n",
      "\tTitle string\n",
      "\tStartDate time.Time\n",
      "\tEndDate time.Time\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\t// Establish a connection to the WebSocket server\n",
      " conn, _, err := upgrader.Upgrade(\"localhost\", \"8080\", \"\")\n",
      " if err != nil {\n",
      " log.Fatal(err)\n",
      " }\n",
      "\n",
      " // Handle incoming messages from the client\n",
      " for {\n",
      " conn.SetReadDeadline(time.Now().Add(30 * time.Second))\n",
      " message, r, err := conn.ReadMessage()\n",
      " if err != nil {\n",
      " log.Println(err)\n",
      " break\n",
      " }\n",
      " switch message := message.(type) {\n",
      " case websocket.TextMessage:\n",
      " fmt.Println(\"Received text message:\", string(message))\n",
      " // Simulate sending a response back to the client\n",
      " sendText(conn, \"Hello from server!\")\n",
      " case websocket.CloseMessage:\n",
      " fmt.Println(\"Received close message:\", string(message))\n",
      " conn.Close()\n",
      " default:\n",
      " log.Println(\"Received unknown message type:\", reflect.TypeOf(message))\n",
      " }\n",
      " }\n",
      "\n",
      " func sendText(w Conn, text string) {\n",
      " msg := websocket.TextMessage{Data: []byte(text)}\n",
      " w.WriteMessage(msg)\n",
      "}\n",
      "\n",
      "func main() {\n",
      "\t// Simulate sending a response back to the client\n",
      " sendText(conn, \"Hello from server!\")\n",
      "}\n",
      "```\n",
      "\n",
      "This code establishes a WebSocket connection with a local server running on `localhost:8080`. It then enters an infinite loop where it listens for incoming messages from the client. When a message is received, it checks the type of message and handles it accordingly:\n",
      "\n",
      "*   If the message is a text message, it prints the message to the console and sends a response back to the client using `sendText`.\n",
      "*   If the message is a close message, it closes the connection.\n",
      "*   For any other message types, it logs an error message.\n",
      "\n",
      "The `sendText` function takes a WebSocket connection (`Conn`) and a text string as arguments. It creates a `websocket.TextMessage` struct with the given text data and sends it back to the client using `w.WriteMessage`.\n",
      "\n",
      "Note that this code is just an example and should not be used in production without proper error handling, security measures, and other best practices.\n",
      "\n",
      "**Language:** The language used in this example is Go (also known as Golang).\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06c25c1d-d205-409e-90a2-179d0bd7c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"fix this issue that waqas raised: Godoc missing for AddRestHandler feature to override the Path\"+\" where can I learn more on gofr to fix this issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "960ad185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like you're having an issue with a Go module or package that's not properly installed or configured, leading to a \"Godoc missing\" error when trying to access documentation for a specific feature.\n",
      "\n",
      "The `AddRestHandler` feature is related to the `net/http` package in Go. To fix the issue, I'll provide some steps you can take:\n",
      "\n",
      "1. **Check your dependencies**: Make sure that the `net/http` and `github.com/gorilla/mux` packages are properly installed. Run `go get -u github.com/gorilla/mux` to update them if necessary.\n",
      "2. **Verify your import statements**: Ensure that your Go file is importing the correct package paths for `AddRestHandler`. The typical import statement for this feature would be:\n",
      "```go\n",
      "import (\n",
      "    \"github.com/gorilla/mux\"\n",
      ")\n",
      "```\n",
      "3. **Check the Gorilla MUX documentation**: Visit the official Gorilla MUX documentation to ensure that you're using the `AddRestHandler` correctly. You can find it at: <https://pkg.gorilla.org/mux/v1.8.0/doc/>\n",
      "4. **GoFR documentation**: The GoFR (Go Framework for Rust) documentation is focused on a different framework, and Gorilla MUX is not part of that ecosystem. However, you can still learn about Gorilla MUX's features, including `AddRestHandler`, by visiting the official Gorilla MUX documentation.\n",
      "\n",
      "If you're still experiencing issues, it might be helpful to:\n",
      "\n",
      "* Check your code for any typos or syntax errors related to `AddRestHandler`.\n",
      "* Review the `net/http` package documentation to ensure that you're using it correctly.\n",
      "* Consider creating a minimal reproducible example (MRE) to help diagnose the issue.\n",
      "\n",
      "To learn more about Gorilla MUX and Go in general, I recommend:\n",
      "\n",
      "* The official Go documentation: <https://golang.org/doc/>\n",
      "* The Gorilla MUX documentation: <https://pkg.gorilla.org/mux/v1.8.0/doc/>\n",
      "* Online courses or tutorials that cover Go programming, such as those on Udemy, Coursera, or edX.\n",
      "\n",
      "If you're still having trouble, feel free to provide more details about your error message and code, and I'll do my best to assist you!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c268270f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
